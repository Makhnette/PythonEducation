# Задание № 3. Вот вам текст:
# «Ну, вышел я, короче, из подъезда. В общем, короче говоря, шел я, 
# кажется, в магазин. Ну,эээ, в общем, было лето, кажется. Как бы тепло. 
# Солнечно, короче. Иду я, иду, в общем, по улице, а тут, короче, яма. 
# Я, эээээ…. Упал в нее. И снова вышел, короче, из подъезда. 
# Ясен пень, в магазин. В общем, лето на дворе, жарко, солнечно, птицы, короче, летают. 
# Кстати, иду я по улице, иду, а тут, короче, яма. Ну, я в нее упал, в общем. 
# Вышел из подъезда, короче. Лето на дворе, ясен пень. 
# Птицы поют, короче, солнечно. В общем, в магазин мне надо. 
# Что-то явно не так, короче. «Рекурсия», - подумал я. 
# Ээээ...короче, в общем, пошел другой дорогой и не упал в эту… ээээ… яму. Хлеба купил».
# Отфильтруйте его, чтобы этот текст можно было нормально прочесть. 
# Предусмотрите вариант, что мусорные слова могли быть написаны без использования запятых.

from posixpath import split
import re

text = 'Ну, вышел я, короче, из подъезда. В общем, короче говоря, шел я, кажется, в магазин. Ну,эээ, в общем, было лето, кажется. Как бы тепло. Солнечно, короче. Иду я, иду, в общем, по улице, а тут, короче, яма. Я, эээээ…. Упал в нее. И снова вышел, короче, из подъезда. Ясен пень, в магазин. В общем, лето на дворе, жарко, солнечно, птицы, короче, летают. Кстати, иду я по улице, иду, а тут, короче, яма. Ну, я в нее упал, в общем. Вышел из подъезда, короче. Лето на дворе, ясен пень. Птицы поют, короче, солнечно. В общем, в магазин мне надо. Что-то явно не так, короче. «Рекурсия», - подумал я. Ээээ...короче, в общем, пошел другой дорогой и не упал в эту… ээээ… яму. Хлеба купил'

trash_words = ['ну', 'в общем', 'эээ', 'кажется', 'ясен пень', 'эээээ', 'короче говоря', 'короче', 'эту..', 'ээ..']

def do_regexp_filter(t: str, tr: str, before: str, after: str):
        cap_tr = tr[0].capitalize() + tr[1:len(tr)]
        reg = before + tr + after
        reg_c = before + cap_tr + after
        t = re.sub(reg, '', t)
        t = re.sub(reg_c, '', t)
        return t


def clean_up_text(t: str):
    res = ''

    t = re.sub(r'…', r'', t)
    t = re.sub(r'(\.{2,})', r' ', t)
    t = re.sub(r'(\Ээ{2,})', r'', t)
    t = re.sub(r'(\э{2,})', r'', t)
            
    for tens in t.split('.'):
        new_tens = tens

        for tr in trash_words:
            new_tens = do_regexp_filter(new_tens, tr, r',(\s+?)', r'(\s+?),')
            new_tens = do_regexp_filter(new_tens, tr, r',', r'(\s+?),')
            new_tens = do_regexp_filter(new_tens, tr, r'', r'(\s+?),')
            new_tens = do_regexp_filter(new_tens, tr, r',(\s+?)', r',')
            new_tens = do_regexp_filter(new_tens, tr, r',(\s+?)', r'')
            new_tens = do_regexp_filter(new_tens, tr, r'', r',')
            new_tens = do_regexp_filter(new_tens, tr, r',', r',')
            new_tens = do_regexp_filter(new_tens, tr, r'', r'')

        new_tens = new_tens.lstrip().rstrip()
        if len(new_tens) > 3:
            res += new_tens[0].capitalize() + new_tens[1: len(new_tens)] + '. '

    return res

print(clean_up_text(text))

